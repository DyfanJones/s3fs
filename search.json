[{"path":[]},{"path":"https://dyfanjones.github.io/s3fs/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://dyfanjones.github.io/s3fs/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://dyfanjones.github.io/s3fs/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"https://dyfanjones.github.io/s3fs/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://dyfanjones.github.io/s3fs/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement dyfan.r.jones@gmail.com. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"https://dyfanjones.github.io/s3fs/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"https://dyfanjones.github.io/s3fs/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"https://dyfanjones.github.io/s3fs/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"https://dyfanjones.github.io/s3fs/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"https://dyfanjones.github.io/s3fs/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"https://dyfanjones.github.io/s3fs/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.1, available https://www.contributor-covenant.org/version/2/1/code_of_conduct.html. Community Impact Guidelines inspired [Mozilla’s code conduct enforcement ladder][https://github.com/mozilla/inclusion]. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"https://dyfanjones.github.io/s3fs/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 Dyfan Jones Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://dyfanjones.github.io/s3fs/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Dyfan Jones. Author, maintainer.","code":""},{"path":"https://dyfanjones.github.io/s3fs/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Jones D (2025). s3fs: 'Amazon Web Service S3' File System. R package version 0.1.7, https://dyfanjones.github.io/s3fs/, https://github.com/DyfanJones/s3fs.","code":"@Manual{,   title = {s3fs: 'Amazon Web Service S3' File System},   author = {Dyfan Jones},   year = {2025},   note = {R package version 0.1.7, https://dyfanjones.github.io/s3fs/},   url = {https://github.com/DyfanJones/s3fs}, }"},{"path":"https://dyfanjones.github.io/s3fs/index.html","id":"s3fs","dir":"","previous_headings":"","what":"Amazon Web Service S3 File System","title":"Amazon Web Service S3 File System","text":"s3fs provides file-system like interface Amazon Web Services R. utilizes paws SDKand R6 ’s core design. repo inspired Python’s s3fs, however ’s API implementation developed follow R’s fs.","code":""},{"path":"https://dyfanjones.github.io/s3fs/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Amazon Web Service S3 File System","text":"can install released version s3fs CRAN : r-universe installation: Github installation","code":"install.packages('s3fs') # Enable repository from dyfanjones options(repos = c(   dyfanjones = 'https://dyfanjones.r-universe.dev',   CRAN = 'https://cloud.r-project.org') )  # Download and install s3fs in R install.packages('s3fs') remotes::install_github(\"dyfanjones/s3fs\")"},{"path":"https://dyfanjones.github.io/s3fs/index.html","id":"dependencies","dir":"","previous_headings":"Installation","what":"Dependencies","title":"Amazon Web Service S3 File System","text":"paws: connection AWS S3 R6: Setup core class data.table: wrangle lists data.frames fs: file system local files lgr: set logging future: set async functionality future.apply: set parallel looping","code":""},{"path":"https://dyfanjones.github.io/s3fs/index.html","id":"comparison-with-fs","dir":"","previous_headings":"","what":"Comparison with fs","title":"Amazon Web Service S3 File System","text":"s3fs attempts give interface fs handling files AWS S3 R. Vectorization. s3fs functions vectorized, accepting multiple path inputs similar fs. Non-async functions return values convey path. Async functions return future object ’s -async counterpart. exception s3_stream_in returns list raw objects. Naming conventions. s3fs functions follows fs naming conventions dir_*, file_* path_* however syntax s3_ infront .e s3_dir_*, s3_file_* s3_path_* etc. Explicit failure. Similar fs failure happens, raised masked warning.","code":""},{"path":"https://dyfanjones.github.io/s3fs/index.html","id":"extra-features","dir":"","previous_headings":"","what":"Extra features:","title":"Amazon Web Service S3 File System","text":"Scalable. s3fs functions designed option run parallel use future future.apply. example: copy large file one location next. s3fs copy large file (> 5GB) using multiparts, future allows multipart run parallel speed process. Async. s3fs uses future create key async functions. focused functions might moving large files R AWS S3. example: Copying large file AWS S3 R.","code":"library(s3fs) library(future)  plan(\"multisession\")  s3_file_copy(\"s3://mybucket/multipart/large_file.csv\", \"s3://mybucket/new_location/large_file.csv\") library(s3fs) library(future)  plan(\"multisession\")  s3_file_copy_async(\"s3://mybucket/multipart/large_file.csv\", \"large_file.csv\")"},{"path":"https://dyfanjones.github.io/s3fs/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Amazon Web Service S3 File System","text":"fs straight forward API 4 core themes: path_ manipulating constructing paths file_ files dir_ directories link_ links s3fs follows theses themes following: s3_path_ manipulating constructing s3 uri paths s3_file_ s3 files s3_dir_ s3 directories NOTE: link_ currently supported. Created 2022-06-21 reprex package (v2.0.1) Similar fs, s3fs designed work well pipe. Created 2022-06-22 reprex package (v2.0.1) NOTE: examples developed fs.","code":"library(s3fs)  # Construct a path to a file with `path()` s3_path(\"foo\", \"bar\", letters[1:3], ext = \"txt\") #> [1] \"s3://foo/bar/a.txt\" \"s3://foo/bar/b.txt\" \"s3://foo/bar/c.txt\"  # list buckets s3_dir_ls() #> [1] \"s3://MyBucket1\" #> [2] \"s3://MyBucket2\"                                         #> [3] \"s3://MyBucket3\"                #> [4] \"s3://MyBucket4\"                             #> [5] \"s3://MyBucket5\"  # list files in bucket s3_dir_ls(\"s3://MyBucket5\") #> [1] \"s3://MyBucket5/iris.json\"     \"s3://MyBucket5/athena-query/\" #> [3] \"s3://MyBucket5/data/\"         \"s3://MyBucket5/default/\"      #> [5] \"s3://MyBucket5/iris/\"         \"s3://MyBucket5/made-up/\"      #> [7] \"s3://MyBucket5/test_df/\"  # create a new directory tmp <- s3_dir_create(s3_file_temp(tmp_dir = \"MyBucket5\")) tmp #> [1] \"s3://MyBucket5/filezwkcxx9q5562\"  # create new files in that directory s3_file_create(s3_path(tmp, \"my-file.txt\")) #> [1] \"s3://MyBucket5/filezwkcxx9q5562/my-file.txt\" s3_dir_ls(tmp) #> [1] \"s3://MyBucket5/filezwkcxx9q5562/my-file.txt\"  # remove files from the directory s3_file_delete(s3_path(tmp, \"my-file.txt\")) s3_dir_ls(tmp) #> character(0)  # remove the directory s3_dir_delete(tmp) library(s3fs) paths <- s3_file_temp(tmp_dir = \"MyBucket\") |>  s3_dir_create() |>  s3_path(letters[1:5]) |>  s3_file_create() paths #> [1] \"s3://MyBucket/fileazqpwujaydqg/a\" #> [2] \"s3://MyBucket/fileazqpwujaydqg/b\" #> [3] \"s3://MyBucket/fileazqpwujaydqg/c\" #> [4] \"s3://MyBucket/fileazqpwujaydqg/d\" #> [5] \"s3://MyBucket/fileazqpwujaydqg/e\"  paths |> s3_file_delete() #> [1] \"s3://MyBucket/fileazqpwujaydqg/a\" #> [2] \"s3://MyBucket/fileazqpwujaydqg/b\" #> [3] \"s3://MyBucket/fileazqpwujaydqg/c\" #> [4] \"s3://MyBucket/fileazqpwujaydqg/d\" #> [5] \"s3://MyBucket/fileazqpwujaydqg/e\""},{"path":"https://dyfanjones.github.io/s3fs/index.html","id":"file-systems-that-emulate-s3","dir":"","previous_headings":"Usage","what":"File systems that emulate S3","title":"Amazon Web Service S3 File System","text":"s3fs allows connect file systems provides S3-compatible interface. example, MinIO offers high-performance, S3 compatible object storage. able connect MinIO server using s3fs::s3_file_system: Created 2022-12-14 reprex v2.0.2 NOTE: want change AWS S3 Minio R session, need set parameter refresh = TRUE calling s3_file_system . can use multiple sessions using R6 class S3FileSystem directly.","code":"library(s3fs)  s3_file_system(   aws_access_key_id = \"minioadmin\",     aws_secret_access_key = \"minioadmin\",   endpoint = \"http://localhost:9000\" )  s3_dir_ls() #> [1] \"\"  s3_bucket_create(\"s3://testbucket\") #> [1] \"s3://testbucket\"  # refresh cache s3_dir_ls(refresh = T) #> [1] \"s3://testbucket\"  s3_bucket_delete(\"s3://testbucket\") #> [1] \"s3://testbucket\"  # refresh cache s3_dir_ls(refresh = T) #> [1] \"\""},{"path":"https://dyfanjones.github.io/s3fs/index.html","id":"feedback-wanted","dir":"","previous_headings":"","what":"Feedback wanted","title":"Amazon Web Service S3 File System","text":"Please open Github ticket raising issues feature requests.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":null,"dir":"Reference","previous_headings":"","what":"Access AWS S3 as if it were a file system. — S3FileSystem","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"creates file system \"like\" API based fs (e.g. dir_ls, file_copy, etc.) AWS S3 storage.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"method update modification time AWS S3 object.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"s3_cache Cache AWS S3 s3_cache_bucket Cached s3 bucket s3_client paws s3 client region_name AWS region creating new connections profile_name name profile use multipart_threshold Threshold use multipart request_payer Threshold use multipart pid Get process ID R Session","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"active-bindings","dir":"Reference","previous_headings":"","what":"Active bindings","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"retries number retries","code":""},{"path":[]},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"S3FileSystem$new() S3FileSystem$file_chmod() S3FileSystem$file_copy() S3FileSystem$file_create() S3FileSystem$file_delete() S3FileSystem$file_download() S3FileSystem$file_exists() S3FileSystem$file_info() S3FileSystem$file_move() S3FileSystem$file_size() S3FileSystem$file_stream_in() S3FileSystem$file_stream_out() S3FileSystem$file_temp() S3FileSystem$file_tag_delete() S3FileSystem$file_tag_info() S3FileSystem$file_tag_update() S3FileSystem$file_touch() S3FileSystem$file_upload() S3FileSystem$file_url() S3FileSystem$file_version_info() S3FileSystem$is_file() S3FileSystem$is_dir() S3FileSystem$is_bucket() S3FileSystem$is_file_empty() S3FileSystem$bucket_chmod() S3FileSystem$bucket_create() S3FileSystem$bucket_delete() S3FileSystem$dir_copy() S3FileSystem$dir_create() S3FileSystem$dir_delete() S3FileSystem$dir_exists() S3FileSystem$dir_download() S3FileSystem$dir_info() S3FileSystem$dir_ls() S3FileSystem$dir_ls_url() S3FileSystem$dir_tree() S3FileSystem$dir_upload() S3FileSystem$path() S3FileSystem$path_dir() S3FileSystem$path_ext() S3FileSystem$path_ext_remove() S3FileSystem$path_ext_set() S3FileSystem$path_file() S3FileSystem$path_join() S3FileSystem$path_split() S3FileSystem$clear_cache() S3FileSystem$clone()","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Initialize S3FileSystem class","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$new(   aws_access_key_id = NULL,   aws_secret_access_key = NULL,   aws_session_token = NULL,   region_name = NULL,   profile_name = NULL,   endpoint = NULL,   disable_ssl = FALSE,   multipart_threshold = fs_bytes(\"2GB\"),   request_payer = FALSE,   anonymous = FALSE,   ... )"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"aws_access_key_id (character): AWS access key ID aws_secret_access_key (character): AWS secret access key aws_session_token (character): AWS temporary session token region_name (character): Default region creating new connections profile_name (character): name profile use. given, default profile used. endpoint (character): complete URL use constructed client. disable_ssl (logical): Whether use SSL. default, SSL used. multipart_threshold (fs_bytes): Threshold use multipart instead standard copy upload methods. request_payer (logical): Confirms requester knows charged request. anonymous (logical): Set anonymous credentials connecting AWS S3. ... parameters within paws client.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-file-chmod-","dir":"Reference","previous_headings":"","what":"Method file_chmod()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Change file permissions","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$file_chmod(   path,   mode = c(\"private\", \"public-read\", \"public-read-write\", \"authenticated-read\",     \"aws-exec-read\", \"bucket-owner-read\", \"bucket-owner-full-control\") )"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): character vector path s3 uri. mode (character): character mode","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-file-copy-","dir":"Reference","previous_headings":"","what":"Method file_copy()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"copy files","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$file_copy(   path,   new_path,   max_batch = fs_bytes(\"100MB\"),   overwrite = FALSE,   ... )"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): path local directory file uri. new_path (character): path local directory file uri. max_batch (fs_bytes): Maximum batch size uploaded multipart. overwrite (logical): Overwrite files exist. FALSE file exists error thrown. ... parameters passed s3_put_object","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-1","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-file-create-","dir":"Reference","previous_headings":"","what":"Method file_create()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Create file AWS S3, file already exists left unchanged.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-3","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$file_create(path, overwrite = FALSE, ...)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-3","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): character vector path s3 uri. overwrite (logical): Overwrite files exist. FALSE file exists error thrown. ... parameters passed s3_put_object","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-2","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-file-delete-","dir":"Reference","previous_headings":"","what":"Method file_delete()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Delete files AWS S3","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-4","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$file_delete(path, ...)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-4","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): character vector paths s3 uris. ... parameters passed s3_delete_objects","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-3","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-file-download-","dir":"Reference","previous_headings":"","what":"Method file_download()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Downloads AWS S3 files local","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-5","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$file_download(path, new_path, overwrite = FALSE, ...)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-5","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): character vector paths uris new_path (character): character vector paths new locations. overwrite (logical): Overwrite files exist. FALSE file exists error thrown. ... parameters passed s3_get_object","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-4","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-file-exists-","dir":"Reference","previous_headings":"","what":"Method file_exists()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Check file exists AWS S3","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-6","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$file_exists(path)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-6","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character) s3 path check","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-5","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"logical vector file exists","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-file-info-","dir":"Reference","previous_headings":"","what":"Method file_info()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Returns file information within AWS S3 directory","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-7","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$file_info(path)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-7","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): character vector paths uris.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-6","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"data.table metadata file. Columns returned follows. bucket_name (character): AWS S3 bucket file key (character): AWS S3 path key file uri (character): S3 uri file size (numeric): file size bytes type (character): file type (file directory) etag (character): entity tag opague identifier last_modified (POSIXct): Created date file. delete_marker (logical): Specifies retrieved logical marker accept_ranges (character): Indicates range bytes specified. expiration (character): File expiration restore (character): file archived archive_status (character): Archive status missing_meta (integer): Number metadata entries returned \"x-amz-meta\" headers version_id (character): version id file cache_control (character): caching behaviour request/reply chain content_disposition (character): presentational information file content_encoding (character): file content encodings content_language (character): language content content_type (character): file MIME type expires (POSIXct): date time file longer cacheable website_redirect_location (character): redirects request file another server_side_encryption (character): File server side encryption metadata (list): metadata file sse_customer_algorithm (character): server-side encryption customer-provided encryption key sse_customer_key_md5 (character): server-side encryption customer-provided encryption key ssekms_key_id (character): ID Amazon Web Services Key Management Service bucket_key_enabled (logical): s3 bucket key server-side encryption storage_class (character): file storage class information request_charged (character): indicates successfully charged request replication_status (character): return specific header request involves bucket either source destination replication rule https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.head_object parts_count (integer): number count parts file object_lock_mode (character): file lock mode object_lock_retain_until_date (POSIXct): date time object_lock_mode expires object_lock_legal_hold_status (character): file legal holding","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-file-move-","dir":"Reference","previous_headings":"","what":"Method file_move()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Move files another location AWS S3","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-8","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$file_move(   path,   new_path,   max_batch = fs_bytes(\"100MB\"),   overwrite = FALSE,   ... )"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-8","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): character vector s3 uri new_path (character): character vector s3 uri. max_batch (fs_bytes): Maximum batch size uploaded multipart. overwrite (logical): Overwrite files exist. FALSE file exists error thrown. ... parameters passed s3_copy_object","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-7","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-file-size-","dir":"Reference","previous_headings":"","what":"Method file_size()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Return file size bytes","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-9","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$file_size(path)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-9","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): character vector s3 uri","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-file-stream-in-","dir":"Reference","previous_headings":"","what":"Method file_stream_in()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Streams AWS S3 file raw vector","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-10","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$file_stream_in(path, ...)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-10","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): character vector paths s3 uri ... parameters passed s3_get_object","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-8","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"list raw vectors containing contents file","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-file-stream-out-","dir":"Reference","previous_headings":"","what":"Method file_stream_out()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Streams raw vector AWS S3 file","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-11","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$file_stream_out(   obj,   path,   max_batch = fs_bytes(\"100MB\"),   overwrite = FALSE,   ... )"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-11","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"obj (raw|character): raw vector, rawConnection, url streamed AWS S3. path (character): character vector paths s3 uri max_batch (fs_bytes): Maximum batch size uploaded multipart. overwrite (logical): Overwrite files exist. FALSE file exists error thrown. ... parameters passed s3_put_object","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-9","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-file-temp-","dir":"Reference","previous_headings":"","what":"Method file_temp()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"return name can used temporary file","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-12","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$file_temp(pattern = \"file\", tmp_dir = \"\", ext = \"\")"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-12","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"pattern (character): character vector non-random portion name. tmp_dir (character): directory file created . ext (character): character vector one paths.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-10","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-file-tag-delete-","dir":"Reference","previous_headings":"","what":"Method file_tag_delete()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Delete file tags","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-13","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$file_tag_delete(path)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-13","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): character vector paths s3 uri ... parameters passed s3_put_object","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-11","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-file-tag-info-","dir":"Reference","previous_headings":"","what":"Method file_tag_info()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Get file tags","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-14","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$file_tag_info(path)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-14","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): character vector paths s3 uri","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-12","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"data.table file version metadata bucket_name (character): AWS S3 bucket file key (character): AWS S3 path key file uri (character): S3 uri file size (numeric): file size bytes version_id (character): version id file tag_key (character): name tag tag_value (character): tag value","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-file-tag-update-","dir":"Reference","previous_headings":"","what":"Method file_tag_update()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Update file tags","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-15","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$file_tag_update(path, tags, overwrite = FALSE)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-15","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): character vector paths s3 uri tags (list): Tags applied overwrite (logical): overwrite tagging modify inplace. Default modify inplace.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-13","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-file-touch-","dir":"Reference","previous_headings":"","what":"Method file_touch()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Similar fs::file_touch create file exist. Use s3fs$file_create() needed.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-16","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$file_touch(path, ...)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-16","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): character vector paths s3 uri ... parameters passed s3_copy_object","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-14","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-file-upload-","dir":"Reference","previous_headings":"","what":"Method file_upload()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Uploads files AWS S3","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-17","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$file_upload(   path,   new_path,   max_batch = fs_bytes(\"100MB\"),   overwrite = FALSE,   ... )"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-17","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): character vector local file paths upload AWS S3 new_path (character): character vector AWS S3 paths uri's new locations. max_batch (fs_bytes): Maximum batch size uploaded multipart. overwrite (logical): Overwrite files exist. FALSE file exists error thrown. ... parameters passed s3_put_object s3_create_multipart_upload","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-15","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-file-url-","dir":"Reference","previous_headings":"","what":"Method file_url()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Generate presigned url S3 object","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-18","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$file_url(path, expiration = 3600L, ...)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-18","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): character vector paths uris expiration (numeric): number seconds presigned url valid . default expires hour (3600 seconds) ... parameters passed s3_get_object","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-16","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"return character urls","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-file-version-info-","dir":"Reference","previous_headings":"","what":"Method file_version_info()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Get file versions","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-19","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$file_version_info(path, ...)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-19","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): character vector paths uris ... parameters passed s3_list_object_versions","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-17","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"return data.table file version info, columns : bucket_name (character): AWS S3 bucket file key (character): AWS S3 path key file uri (character): S3 uri file size (numeric): file size bytes version_id (character): version id file owner (character): file owner etag (character): entity tag opague identifier last_modified (POSIXct): Created date file.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-is-file-","dir":"Reference","previous_headings":"","what":"Method is_file()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Test file types","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-20","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$is_file(path)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-20","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): character vector paths uris","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-18","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"logical vector object file","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-is-dir-","dir":"Reference","previous_headings":"","what":"Method is_dir()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Test file types","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-21","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$is_dir(path)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-21","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): character vector paths uris","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-19","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"logical vector object directory","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-is-bucket-","dir":"Reference","previous_headings":"","what":"Method is_bucket()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Test file types","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-22","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$is_bucket(path, ...)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-22","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): character vector paths uris ... parameters passed s3_list_objects_v2","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-20","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"logical vector object AWS S3 bucket","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-is-file-empty-","dir":"Reference","previous_headings":"","what":"Method is_file_empty()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Test file types","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-23","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$is_file_empty(path)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-23","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): character vector paths uris","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-21","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"logical vector file empty","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-bucket-chmod-","dir":"Reference","previous_headings":"","what":"Method bucket_chmod()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Change bucket permissions","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-24","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$bucket_chmod(   path,   mode = c(\"private\", \"public-read\", \"public-read-write\", \"authenticated-read\") )"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-24","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): character vector path s3 uri. mode (character): character mode","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-22","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-bucket-create-","dir":"Reference","previous_headings":"","what":"Method bucket_create()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Create bucket","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-25","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$bucket_create(   path,   region_name = NULL,   mode = c(\"private\", \"public-read\", \"public-read-write\", \"authenticated-read\"),   versioning = FALSE,   ... )"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-25","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): character vector path s3 uri. region_name (character): aws region mode (character): character mode versioning (logical): Whether set bucket versioning . ... parameters passed s3_create_bucket","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-23","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-bucket-delete-","dir":"Reference","previous_headings":"","what":"Method bucket_delete()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Delete bucket","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-26","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$bucket_delete(path)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-26","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): character vector path s3 uri.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-dir-copy-","dir":"Reference","previous_headings":"","what":"Method dir_copy()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Copies directory recursively new location.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-27","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$dir_copy(   path,   new_path,   max_batch = fs_bytes(\"100MB\"),   overwrite = FALSE,   ... )"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-27","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): path local directory file uri. new_path (character): path local directory file uri. max_batch (fs_bytes): Maximum batch size uploaded multipart. overwrite (logical): Overwrite files exist. FALSE file exists error thrown. ... parameters passed s3_put_object s3_create_multipart_upload","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-24","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-dir-create-","dir":"Reference","previous_headings":"","what":"Method dir_create()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Create empty directory","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-28","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$dir_create(path, overwrite = FALSE, ...)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-28","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): vector directory uri created AWS S3 overwrite (logical): Overwrite files exist. FALSE file exists error thrown. ... parameters passed s3_put_object","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-25","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-dir-delete-","dir":"Reference","previous_headings":"","what":"Method dir_delete()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Delete contents directory AWS S3","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-29","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$dir_delete(path)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-29","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): vector paths uris directories deleted.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-26","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-dir-exists-","dir":"Reference","previous_headings":"","what":"Method dir_exists()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Check path exists AWS S3","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-30","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$dir_exists(path = \".\")"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-30","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character) aws s3 path checked","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-27","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-dir-download-","dir":"Reference","previous_headings":"","what":"Method dir_download()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Downloads AWS S3 files local","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-31","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$dir_download(path, new_path, overwrite = FALSE, ...)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-31","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): character vector paths uris new_path (character): character vector paths new locations. Please ensure directories end /. overwrite (logical): Overwrite files exist. FALSE file exists error thrown. ... parameters passed s3_get_object","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-28","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-dir-info-","dir":"Reference","previous_headings":"","what":"Method dir_info()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Returns file information within AWS S3 directory","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-32","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$dir_info(   path = \".\",   type = c(\"any\", \"bucket\", \"directory\", \"file\"),   glob = NULL,   regexp = NULL,   invert = FALSE,   recurse = FALSE,   refresh = FALSE,   ... )"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-32","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character):character vector one paths. Can path s3 uri. type (character): File type(s) return. Default (\"\") returns AWS S3 object types. glob (character): wildcard pattern (e.g. *.csv), passed onto grep() filter paths. regexp (character): regular expression (e.g. [.]csv$), passed onto grep() filter paths. invert (logical): code return files match. recurse (logical): Returns AWS S3 objects lower sub directories refresh (logical): Refresh cached s3_cache. ... parameters passed s3_list_objects_v2","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-29","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"data.table directory metadata bucket_name (character): AWS S3 bucket file key (character): AWS S3 path key file uri (character): S3 uri file size (numeric): file size bytes version_id (character): version id file etag (character): entity tag opague identifier last_modified (POSIXct): Created date file","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-dir-ls-","dir":"Reference","previous_headings":"","what":"Method dir_ls()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Returns file name within AWS S3 directory","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-33","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$dir_ls(   path = \".\",   type = c(\"any\", \"bucket\", \"directory\", \"file\"),   glob = NULL,   regexp = NULL,   invert = FALSE,   recurse = FALSE,   refresh = FALSE,   ... )"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-33","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character):character vector one paths. Can path s3 uri. type (character): File type(s) return. Default (\"\") returns AWS S3 object types. glob (character): wildcard pattern (e.g. *.csv), passed onto grep() filter paths. regexp (character): regular expression (e.g. [.]csv$), passed onto grep() filter paths. invert (logical): code return files match. recurse (logical): Returns AWS S3 objects lower sub directories refresh (logical): Refresh cached s3_cache. ... parameters passed s3_list_objects_v2","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-30","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-dir-ls-url-","dir":"Reference","previous_headings":"","what":"Method dir_ls_url()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Generate presigned url list S3 directories","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-34","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$dir_ls_url(path, expiration = 3600L, recurse = FALSE, ...)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-34","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): character vector paths uris expiration (numeric): number seconds presigned url valid . default expires hour (3600 seconds) recurse (logical): Returns AWS S3 objects lower sub directories ... parameters passed s3_list_objects_v2","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-31","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"return character urls","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-dir-tree-","dir":"Reference","previous_headings":"","what":"Method dir_tree()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Print contents directories tree-like format","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-35","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$dir_tree(path, recurse = TRUE, ...)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-35","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): path path print tree recurse (logical): Returns AWS S3 objects lower sub directories ... Additional arguments passed s3_dir_ls.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-32","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-dir-upload-","dir":"Reference","previous_headings":"","what":"Method dir_upload()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Uploads local directory AWS S3","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-36","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$dir_upload(   path,   new_path,   max_batch = fs_bytes(\"100MB\"),   overwrite = FALSE,   ... )"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-36","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): character vector local file paths upload AWS S3 new_path (character): character vector AWS S3 paths uri's new locations. max_batch (fs_bytes): Maximum batch size uploaded multipart. overwrite (logical): Overwrite files exist. FALSE file exists error thrown. ... parameters passed s3_put_object s3_create_multipart_upload","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-33","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-path-","dir":"Reference","previous_headings":"","what":"Method path()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Constructs s3 uri path","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-37","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$path(..., ext = \"\")"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-37","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"... (character): Character vectors ext (character): optional extension append generated path","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-34","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-path-dir-","dir":"Reference","previous_headings":"","what":"Method path_dir()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Returns directory portion s3 uri","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-38","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$path_dir(path)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-38","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): character vector paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-35","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-path-ext-","dir":"Reference","previous_headings":"","what":"Method path_ext()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Returns last extension path.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-39","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$path_ext(path)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-39","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): character vector paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-36","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"character s3 uri file extension","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-path-ext-remove-","dir":"Reference","previous_headings":"","what":"Method path_ext_remove()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Removes last extension return rest s3 uri.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-40","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$path_ext_remove(path)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-40","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): character vector paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-37","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-path-ext-set-","dir":"Reference","previous_headings":"","what":"Method path_ext_set()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Replace extension new extension.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-41","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$path_ext_set(path, ext)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-41","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): character vector paths ext (character): New file extension","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-38","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-path-file-","dir":"Reference","previous_headings":"","what":"Method path_file()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Returns file name portion s3 uri path","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-42","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$path_file(path)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-42","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): character vector paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-39","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"character vector file names","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-path-join-","dir":"Reference","previous_headings":"","what":"Method path_join()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Construct s3 uri path path vector","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-43","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$path_join(parts)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-43","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"parts (character): character vector one paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-40","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-path-split-","dir":"Reference","previous_headings":"","what":"Method path_split()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Split s3 uri path core components bucket, key version id","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-44","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$path_split(path)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-44","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): character vector one paths s3 uri","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"returns-41","dir":"Reference","previous_headings":"","what":"Returns","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"list character vectors splitting s3 uri path \"Bucket\", \"Key\" \"VersionId\"","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-clear-cache-","dir":"Reference","previous_headings":"","what":"Method clear_cache()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"Clear S3 Cache","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-45","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$clear_cache(path = NULL)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-45","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"path (character): s3 path cl","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"objects class cloneable method.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"usage-46","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"","code":"S3FileSystem$clone(deep = FALSE)"},{"path":"https://dyfanjones.github.io/s3fs/reference/S3FileSystem.html","id":"arguments-46","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — S3FileSystem","text":"deep Whether make deep clone.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/copy.html","id":null,"dir":"Reference","previous_headings":"","what":"Copy files and directories — copy","title":"Copy files and directories — copy","text":"s3_file_copy copies files s3_dir_copy copies directory recursively new location","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/copy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Copy files and directories — copy","text":"","code":"s3_file_copy(   path,   new_path,   max_batch = fs_bytes(\"100MB\"),   overwrite = FALSE,   ... )  s3_dir_copy(   path,   new_path,   max_batch = fs_bytes(\"100MB\"),   overwrite = FALSE,   ... )"},{"path":"https://dyfanjones.github.io/s3fs/reference/copy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Copy files and directories — copy","text":"path (character): path local directory file uri. new_path (character): path local directory file uri. max_batch (fs_bytes): Maximum batch size uploaded multipart. overwrite (logical): Overwrite files exist. FALSE file exists error thrown. ... parameters passed s3_put_object","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/copy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Copy files and directories — copy","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/copy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Copy files and directories — copy","text":"","code":"if (FALSE) { # \\dontrun{ # Require AWS S3 credentials  temp_file = \"temp.txt\" file.create(temp_file)  s3_file_copy(     temp_file,     \"s3://MyBucket/temp_file.txt\"  ) } # }"},{"path":"https://dyfanjones.github.io/s3fs/reference/copy_async.html","id":null,"dir":"Reference","previous_headings":"","what":"Copy files and directories — copy_async","title":"Copy files and directories — copy_async","text":"s3_file_copy copies files s3_dir_copy copies directory recursively new location","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/copy_async.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Copy files and directories — copy_async","text":"","code":"s3_file_copy_async(   path,   new_path,   max_batch = fs_bytes(\"100MB\"),   overwrite = FALSE,   ... )  s3_dir_copy_async(   path,   new_path,   max_batch = fs_bytes(\"100MB\"),   overwrite = FALSE,   ... )"},{"path":"https://dyfanjones.github.io/s3fs/reference/copy_async.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Copy files and directories — copy_async","text":"path (character): path local directory file uri. new_path (character): path local directory file uri. max_batch (fs_bytes): Maximum batch size uploaded multipart. overwrite (logical): Overwrite files exist. FALSE file exists error thrown. ... parameters passed s3_put_object","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/copy_async.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Copy files and directories — copy_async","text":"return future object s3_file_copy(), s3_dir_copy()","code":""},{"path":[]},{"path":"https://dyfanjones.github.io/s3fs/reference/create.html","id":null,"dir":"Reference","previous_headings":"","what":"Create files and directories — create","title":"Create files and directories — create","text":"s3_file_create create file AWS S3, file already exists left unchanged. s3_dir_create create empty directory AWS S3.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/create.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create files and directories — create","text":"","code":"s3_file_create(path, overwrite = FALSE, ...)  s3_bucket_create(   path,   region_name = NULL,   mode = c(\"private\", \"public-read\", \"public-read-write\", \"authenticated-read\"),   versioning = FALSE,   ... )  s3_dir_create(path, overwrite = FALSE, ...)"},{"path":"https://dyfanjones.github.io/s3fs/reference/create.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create files and directories — create","text":"path (character): character vector path s3 uri. overwrite (logical): Overwrite files exist. FALSE file exists error thrown. ... parameters passed s3_put_object, s3_create_bucket region_name (character): region AWS S3 bucket, defaults s3_file_system() class region. mode (character): character mode versioning (logical)","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/create.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create files and directories — create","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/create.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create files and directories — create","text":"","code":"if (FALSE) { # \\dontrun{ # Require AWS S3 credentials  temp_file = s3_file_temp(tmp_dir= \"MyBucket\") s3_file_create(temp_file) } # }"},{"path":"https://dyfanjones.github.io/s3fs/reference/delete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete files and directories — delete","title":"Delete files and directories — delete","text":"s3_file_delete delete files AWS S3 s3_dir_delete delete directories AWS S3 recursively.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/delete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete files and directories — delete","text":"","code":"s3_file_delete(path, ...)  s3_dir_delete(path)"},{"path":"https://dyfanjones.github.io/s3fs/reference/delete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete files and directories — delete","text":"path (character): character vector paths s3 uris. ... parameters passed s3_delete_objects","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/delete.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Delete files and directories — delete","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/delete.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Delete files and directories — delete","text":"","code":"if (FALSE) { # \\dontrun{ # Require AWS S3 credentials  temp_file = s3_file_temp(tmp_dir= \"MyBucket\") s3_file_create(temp_file)  s3_file_delete(temp_file) } # }"},{"path":"https://dyfanjones.github.io/s3fs/reference/delete_async.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete files and directories — delete_async","title":"Delete files and directories — delete_async","text":"s3_file_delete delete files AWS S3 s3_dir_delete delete directories AWS S3 recursively.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/delete_async.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete files and directories — delete_async","text":"","code":"s3_file_delete_async(path, ...)  s3_dir_delete_async(path)"},{"path":"https://dyfanjones.github.io/s3fs/reference/delete_async.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete files and directories — delete_async","text":"path (character): character vector paths s3 uris. ... parameters passed s3_delete_objects","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/delete_async.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Delete files and directories — delete_async","text":"return future object s3_file_delete() s3_dir_delete()","code":""},{"path":[]},{"path":"https://dyfanjones.github.io/s3fs/reference/download.html","id":null,"dir":"Reference","previous_headings":"","what":"Download files and directories — download","title":"Download files and directories — download","text":"s3_file_download downloads AWS S3 files local s3_file_download downloads AWS s3 directory local","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/download.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download files and directories — download","text":"","code":"s3_file_download(path, new_path, overwrite = FALSE, ...)  s3_dir_download(path, new_path, overwrite = FALSE, ...)"},{"path":"https://dyfanjones.github.io/s3fs/reference/download.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download files and directories — download","text":"path (character): character vector paths uris new_path (character): character vector paths new locations. overwrite (logical): Overwrite files exist. FALSE file exists error thrown. ... parameters passed s3_get_object","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/download.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download files and directories — download","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/download.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download files and directories — download","text":"","code":"if (FALSE) { # \\dontrun{ # Require AWS S3 credentials  temp_file = s3_file_temp(tmp_dir= \"MyBucket\") s3_file_create(temp_file)  s3_file_download(temp_file, \"temp_file.txt\") } # }"},{"path":"https://dyfanjones.github.io/s3fs/reference/download_async.html","id":null,"dir":"Reference","previous_headings":"","what":"Download files and directories — download_async","title":"Download files and directories — download_async","text":"s3_file_download downloads AWS S3 files local s3_file_download downloads AWS s3 directory local","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/download_async.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download files and directories — download_async","text":"","code":"s3_file_download_async(path, new_path, overwrite = FALSE, ...)  s3_dir_download_async(path, new_path, overwrite = FALSE, ...)"},{"path":"https://dyfanjones.github.io/s3fs/reference/download_async.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download files and directories — download_async","text":"path (character): character vector paths uris new_path (character): character vector paths new locations. overwrite (logical): Overwrite files exist. FALSE file exists error thrown. ... parameters passed s3_get_object","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/download_async.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download files and directories — download_async","text":"return future object s3_file_download() s3_dir_download()","code":""},{"path":[]},{"path":"https://dyfanjones.github.io/s3fs/reference/exists.html","id":null,"dir":"Reference","previous_headings":"","what":"Download files and directories — exists","title":"Download files and directories — exists","text":"s3_file_exists check file exists AWS S3 s3_dir_exists check path directory AWS S3","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/exists.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download files and directories — exists","text":"","code":"s3_file_exists(path)  s3_dir_exists(path = \".\")"},{"path":"https://dyfanjones.github.io/s3fs/reference/exists.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download files and directories — exists","text":"path (character) s3 path check","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/exists.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download files and directories — exists","text":"logical vector file exists","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/exists.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download files and directories — exists","text":"","code":"if (FALSE) { # \\dontrun{ # Require AWS S3 credentials  temp_file = s3_file_temp(tmp_dir= \"MyBucket\") s3_file_create(temp_file)  s3_file_exists(temp_file) } # }"},{"path":"https://dyfanjones.github.io/s3fs/reference/file_type.html","id":null,"dir":"Reference","previous_headings":"","what":"Functions to test for file types — file_type","title":"Functions to test for file types — file_type","text":"Test file types","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/file_type.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Functions to test for file types — file_type","text":"","code":"s3_is_file(path)  s3_is_dir(path)  s3_is_bucket(path, ...)  s3_is_file_empty(path)"},{"path":"https://dyfanjones.github.io/s3fs/reference/file_type.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Functions to test for file types — file_type","text":"path (character): character vector paths uris ... parameters passed s3_list_objects_v2","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/info.html","id":null,"dir":"Reference","previous_headings":"","what":"Get files and directories information — info","title":"Get files and directories information — info","text":"s3_file_info returns file information within AWS S3 directory s3_file_size returns file size bytes s3_dir_info returns file name information within AWS S3 directory s3_dir_ls returns file name within AWS S3 directory","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get files and directories information — info","text":"","code":"s3_file_info(path)  s3_file_size(path)  s3_dir_info(   path = \".\",   type = c(\"any\", \"bucket\", \"directory\", \"file\"),   glob = NULL,   regexp = NULL,   invert = FALSE,   recurse = FALSE,   refresh = FALSE,   ... )  s3_dir_ls(   path = \".\",   type = c(\"any\", \"bucket\", \"directory\", \"file\"),   glob = NULL,   regexp = NULL,   invert = FALSE,   recurse = FALSE,   refresh = FALSE,   ... )"},{"path":"https://dyfanjones.github.io/s3fs/reference/info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get files and directories information — info","text":"path (character):character vector one paths. Can path s3 uri. type (character): File type(s) return. Default (\"\") returns AWS S3 object types. glob (character): wildcard pattern (e.g. *.csv), passed onto grep() filter paths. regexp (character): regular expression (e.g. [.]csv$), passed onto grep() filter paths. invert (logical): code return files match. recurse (logical): Returns AWS S3 objects lower sub directories refresh (logical): Refresh cached s3_cache. ... parameters passed s3_list_objects_v2","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/info.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get files and directories information — info","text":"s3_file_info data.table metadata file. Columns returned follows. bucket_name (character): AWS S3 bucket file key (character): AWS S3 path key file uri (character): S3 uri file size (numeric): file size bytes type (character): file type (file directory) etag (character): entity tag opague identifier last_modified (POSIXct): Created date file. delete_marker (logical): Specifies retrieved logical marker accept_ranges (character): Indicates range bytes specified. expiration (character): File expiration restore (character): file archived archive_status (character): Archive status missing_meta (integer): Number metadata entries returned \"x-amz-meta\" headers version_id (character): version id file cache_control (character): caching behaviour request/reply chain content_disposition (character): presentational information file content_encoding (character): file content encodings content_language (character): language content content_type (character): file MIME type expires (POSIXct): date time file longer cacheable website_redirect_location (character): redirects request file another server_side_encryption (character): File server side encryption metadata (list): metadata file sse_customer_algorithm (character): server-side encryption customer-provided encryption key sse_customer_key_md5 (character): server-side encryption customer-provided encryption key ssekms_key_id (character): ID Amazon Web Services Key Management Service bucket_key_enabled (logical): s3 bucket key server-side encryption storage_class (character): file storage class information request_charged (character): indicates successfully charged request replication_status (character): return specific header request involves bucket either source destination replication rule https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.head_object parts_count (integer): number count parts file object_lock_mode (character): file lock mode object_lock_retain_until_date (POSIXct): date time object_lock_mode expires object_lock_legal_hold_status (character): file legal holding s3_dir_info data.table directory metadata bucket_name (character): AWS S3 bucket file key (character): AWS S3 path key file uri (character): S3 uri file size (numeric): file size bytes version_id (character): version id file etag (character): entity tag opague identifier last_modified (POSIXct): Created date file s3_dir_ls character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/info.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get files and directories information — info","text":"","code":"if (FALSE) { # \\dontrun{ # Require AWS S3 credentials  temp_file = s3_file_temp(tmp_dir= \"MyBucket\") s3_file_create(temp_file)  s3_file_info(temp_file) } # }"},{"path":"https://dyfanjones.github.io/s3fs/reference/path.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct path for file or directory — path","title":"Construct path for file or directory — path","text":"Constructs s3 uri path","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/path.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct path for file or directory — path","text":"","code":"s3_path(..., ext = \"\")"},{"path":"https://dyfanjones.github.io/s3fs/reference/path.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct path for file or directory — path","text":"... (character): Character vectors ext (character): optional extension append generated path","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/path.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct path for file or directory — path","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/path.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct path for file or directory — path","text":"","code":"if (FALSE) { # \\dontrun{ # Require AWS S3 credentials  s3_path(\"my_bucket1\", \"my_bucket2\") } # }"},{"path":"https://dyfanjones.github.io/s3fs/reference/path_manipulate.html","id":null,"dir":"Reference","previous_headings":"","what":"Manipulate s3 uri paths — path_manipulate","title":"Manipulate s3 uri paths — path_manipulate","text":"s3_path_dir returns directory portion s3 uri s3_path_file returns file name portion s3 uri path s3_path_ext returns last extension path. s3_path_ext_remove removes last extension return rest s3 uri. s3_path_ext_set replace extension new extension.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/path_manipulate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Manipulate s3 uri paths — path_manipulate","text":"","code":"s3_path_dir(path)  s3_path_file(path)  s3_path_ext(path)  s3_path_ext_remove(path)  s3_path_ext_set(path, ext)"},{"path":"https://dyfanjones.github.io/s3fs/reference/path_manipulate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Manipulate s3 uri paths — path_manipulate","text":"path (character): character vector paths ext (character): New file extension","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/path_manipulate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Manipulate s3 uri paths — path_manipulate","text":"","code":"if (FALSE) { # \\dontrun{ # Require AWS S3 credentials  s3_path_dir(\"s3://my_bucket1/hi.txt\")  s3_path_file(\"s3://my_bucket1/hi.txt\") } # }"},{"path":"https://dyfanjones.github.io/s3fs/reference/permission.html","id":null,"dir":"Reference","previous_headings":"","what":"Change file permissions — permission","title":"Change file permissions — permission","text":"Change file permissions","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/permission.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Change file permissions — permission","text":"","code":"s3_file_chmod(   path,   mode = c(\"private\", \"public-read\", \"public-read-write\", \"authenticated-read\",     \"aws-exec-read\", \"bucket-owner-read\", \"bucket-owner-full-control\") )  s3_bucket_chmod(   path,   mode = c(\"private\", \"public-read\", \"public-read-write\", \"authenticated-read\") )"},{"path":"https://dyfanjones.github.io/s3fs/reference/permission.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Change file permissions — permission","text":"path (character): character vector path s3 uri. mode (character): character mode","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/permission.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Change file permissions — permission","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/permission.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Change file permissions — permission","text":"","code":"if (FALSE) { # \\dontrun{ # Require AWS S3 credentials  temp_file = s3_file_temp(tmp_dir = \"MyBucket\") s3_file_create(temp_file)  # Reset connection to connect to a different region s3_file_chmod(     profile_name = \"s3fs_example\",     region_name = \"us-east-1\",     refresh = TRUE  ) } # }"},{"path":"https://dyfanjones.github.io/s3fs/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. fs fs_bytes","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_bucket_delete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete bucket — s3_bucket_delete","title":"Delete bucket — s3_bucket_delete","text":"Delete AWS S3 bucket including objects bucket .","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_bucket_delete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete bucket — s3_bucket_delete","text":"","code":"s3_bucket_delete(path)"},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_bucket_delete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete bucket — s3_bucket_delete","text":"path (character): character vector path s3 uri.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_dir_ls_url.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate presigned url to list S3 directories — s3_dir_ls_url","title":"Generate presigned url to list S3 directories — s3_dir_ls_url","text":"Generate presigned url list S3 directories","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_dir_ls_url.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate presigned url to list S3 directories — s3_dir_ls_url","text":"","code":"s3_dir_ls_url(path, expiration = 3600L, recurse = FALSE, ...)"},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_dir_ls_url.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate presigned url to list S3 directories — s3_dir_ls_url","text":"path (character): character vector paths uris expiration (numeric): number seconds presigned url valid . default expires hour (3600 seconds) recurse (logical): Returns AWS S3 objects lower sub directories ... parameters passed s3_list_objects_v2","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_dir_ls_url.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate presigned url to list S3 directories — s3_dir_ls_url","text":"return character urls","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_dir_tree.html","id":null,"dir":"Reference","previous_headings":"","what":"Print contents of directories in a tree-like format — s3_dir_tree","title":"Print contents of directories in a tree-like format — s3_dir_tree","text":"Print contents directories tree-like format","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_dir_tree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print contents of directories in a tree-like format — s3_dir_tree","text":"","code":"s3_dir_tree(path, recurse = TRUE, ...)"},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_dir_tree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print contents of directories in a tree-like format — s3_dir_tree","text":"path (character): path path print tree recurse (logical): Returns AWS S3 objects lower sub directories ... Additional arguments passed s3_dir_ls.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_dir_tree.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print contents of directories in a tree-like format — s3_dir_tree","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_file_move.html","id":null,"dir":"Reference","previous_headings":"","what":"Move or rename S3 files — s3_file_move","title":"Move or rename S3 files — s3_file_move","text":"Move files another location AWS S3","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_file_move.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Move or rename S3 files — s3_file_move","text":"","code":"s3_file_move(path, new_path, max_batch = 100 * MB, overwrite = FALSE, ...)"},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_file_move.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Move or rename S3 files — s3_file_move","text":"path (character): character vector s3 uri new_path (character): character vector s3 uri. max_batch (numeric): Maximum batch size uploaded multipart. overwrite (logical): Overwrite files exist. FALSE file exists error thrown. ... parameters passed s3_copy_object","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_file_move.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Move or rename S3 files — s3_file_move","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_file_move.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Move or rename S3 files — s3_file_move","text":"","code":"if (FALSE) { # \\dontrun{ # Require AWS S3 credentials  temp_file = s3_file_temp(tmp_dir= \"MyBucket\") s3_file_create(temp_file)  s3_file_move(temp_file, \"s3://MyBucket/new_file.txt\") } # }"},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_file_move_async.html","id":null,"dir":"Reference","previous_headings":"","what":"Move or rename S3 files — s3_file_move_async","title":"Move or rename S3 files — s3_file_move_async","text":"Move files another location AWS S3","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_file_move_async.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Move or rename S3 files — s3_file_move_async","text":"","code":"s3_file_move_async(   path,   new_path,   max_batch = 100 * MB,   overwrite = FALSE,   ... )"},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_file_move_async.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Move or rename S3 files — s3_file_move_async","text":"path (character): character vector s3 uri new_path (character): character vector s3 uri. max_batch (numeric): Maximum batch size uploaded multipart. overwrite (logical): Overwrite files exist. FALSE file exists error thrown. ... parameters passed s3_copy_object","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_file_move_async.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Move or rename S3 files — s3_file_move_async","text":"return future object s3_file_move()","code":""},{"path":[]},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_file_system.html","id":null,"dir":"Reference","previous_headings":"","what":"Access AWS S3 as if it were a file system. — s3_file_system","title":"Access AWS S3 as if it were a file system. — s3_file_system","text":"creates file system \"like\" API based fs (e.g. dir_ls, file_copy, etc.) AWS S3 storage. set AWS credentials please look https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_file_system.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Access AWS S3 as if it were a file system. — s3_file_system","text":"","code":"s3_file_system(   aws_access_key_id = NULL,   aws_secret_access_key = NULL,   aws_session_token = NULL,   region_name = NULL,   profile_name = NULL,   endpoint = NULL,   disable_ssl = FALSE,   multipart_threshold = fs_bytes(\"2GB\"),   request_payer = FALSE,   anonymous = FALSE,   retries = 5,   refresh = FALSE,   ... )"},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_file_system.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access AWS S3 as if it were a file system. — s3_file_system","text":"aws_access_key_id (character): AWS access key ID aws_secret_access_key (character): AWS secret access key aws_session_token (character): AWS temporary session token region_name (character): Default region creating new connections profile_name (character): name profile use. given, default profile used. endpoint (character): complete URL use constructed client. disable_ssl (logical): Whether use SSL. default, SSL used. multipart_threshold (fs_bytes): Threshold use multipart instead standard copy upload methods. request_payer (logical): Confirms requester knows charged request. anonymous (logical): Set anonymous credentials connecting AWS S3. retries (numeric): max number retry attempts refresh (logical): Refresh cached S3FileSystem class ... parameters within paws client.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_file_system.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Access AWS S3 as if it were a file system. — s3_file_system","text":"S3FileSystem class invisible","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_file_system.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Access AWS S3 as if it were a file system. — s3_file_system","text":"","code":"if (FALSE) { # \\dontrun{ # Require AWS S3 credentials  # Set up connection using profile s3_file_system(profile_name = \"s3fs_example\")  # Reset connection to connect to a different region s3_file_system(     profile_name = \"s3fs_example\",     region_name = \"us-east-1\",     refresh = TRUE  ) } # }"},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_file_temp.html","id":null,"dir":"Reference","previous_headings":"","what":"Create name for temporary files — s3_file_temp","title":"Create name for temporary files — s3_file_temp","text":"return name can used temporary file","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_file_temp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create name for temporary files — s3_file_temp","text":"","code":"s3_file_temp(pattern = \"file\", tmp_dir = \"\", ext = \"\")"},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_file_temp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create name for temporary files — s3_file_temp","text":"pattern (character): character vector non-random portion name. tmp_dir (character): directory file created . default cached s3 bucket applied otherwise \"\" used. ext (character): character vector one paths.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_file_temp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create name for temporary files — s3_file_temp","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_file_temp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create name for temporary files — s3_file_temp","text":"","code":"if (FALSE) { # \\dontrun{ # Require AWS S3 credentials  s3_file_temp(tmp_dir = \"MyBucket\") } # }"},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_file_url.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate presigned url for S3 object — s3_file_url","title":"Generate presigned url for S3 object — s3_file_url","text":"Generate presigned url S3 object","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_file_url.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate presigned url for S3 object — s3_file_url","text":"","code":"s3_file_url(path, expiration = 3600L, ...)"},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_file_url.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate presigned url for S3 object — s3_file_url","text":"path (character): character vector paths uris expiration (numeric): number seconds presigned url valid . default expires hour (3600 seconds) ... parameters passed params parameter s3_generate_presigned_url","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_file_url.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate presigned url for S3 object — s3_file_url","text":"return character urls","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_file_version_info.html","id":null,"dir":"Reference","previous_headings":"","what":"Query file version metadata — s3_file_version_info","title":"Query file version metadata — s3_file_version_info","text":"Get file versions","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_file_version_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Query file version metadata — s3_file_version_info","text":"","code":"s3_file_version_info(path, ...)"},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_file_version_info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Query file version metadata — s3_file_version_info","text":"path (character): character vector paths uris ... parameters passed s3_list_object_versions","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_path_join.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct AWS S3 path — s3_path_join","title":"Construct AWS S3 path — s3_path_join","text":"Construct s3 uri path path vector","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_path_join.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct AWS S3 path — s3_path_join","text":"","code":"s3_path_join(path)"},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_path_join.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct AWS S3 path — s3_path_join","text":"path (character): character vector one paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_path_join.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct AWS S3 path — s3_path_join","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_path_join.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct AWS S3 path — s3_path_join","text":"","code":"if (FALSE) { # \\dontrun{ # Require AWS S3 credentials  s3_path_dir(c(\"s3://my_bucket1/hi.txt\", \"s3://my_bucket/bye.txt\")) } # }"},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_path_split.html","id":null,"dir":"Reference","previous_headings":"","what":"Split s3 path and uri — s3_path_split","title":"Split s3 path and uri — s3_path_split","text":"Split s3 uri path core components bucket, key version id","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_path_split.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split s3 path and uri — s3_path_split","text":"","code":"s3_path_split(path)"},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_path_split.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split s3 path and uri — s3_path_split","text":"path (character): character vector one paths s3 uri","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_path_split.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split s3 path and uri — s3_path_split","text":"list character vectors splitting s3 uri path \"Bucket\", \"Key\" \"VersionId\"","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/s3_path_split.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Split s3 path and uri — s3_path_split","text":"","code":"if (FALSE) { # \\dontrun{ # Require AWS S3 credentials  s3_path_dir(\"s3://my_bucket1/hi.txt\") } # }"},{"path":"https://dyfanjones.github.io/s3fs/reference/s3fs-package.html","id":null,"dir":"Reference","previous_headings":"","what":"s3fs: 'Amazon Web Service S3' File System — s3fs-package","title":"s3fs: 'Amazon Web Service S3' File System — s3fs-package","text":"Access 'Amazon Web Service Simple Storage Service' ('S3') https://aws.amazon.com/s3/ file system. Interface based R package 'fs'.","code":""},{"path":[]},{"path":"https://dyfanjones.github.io/s3fs/reference/s3fs-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"s3fs: 'Amazon Web Service S3' File System — s3fs-package","text":"Maintainer: Dyfan Jones dyfan.r.jones@gmail.com","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/stream.html","id":null,"dir":"Reference","previous_headings":"","what":"Streams data from R to AWS S3. — stream","title":"Streams data from R to AWS S3. — stream","text":"s3_file_stream_in streams AWS S3 file raw vector s3_file_stream_out streams raw vector AWS S3 file","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/stream.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Streams data from R to AWS S3. — stream","text":"","code":"s3_file_stream_in(path, ...)  s3_file_stream_out(   obj,   path,   max_batch = fs_bytes(\"100MB\"),   overwrite = FALSE,   ... )"},{"path":"https://dyfanjones.github.io/s3fs/reference/stream.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Streams data from R to AWS S3. — stream","text":"path (character): character vector paths s3 uri ... parameters passed s3_get_object s3_put_object obj (raw|character): raw vector, rawConnection, url streamed AWS S3. max_batch (fs_bytes): Maximum batch size uploaded multipart. overwrite (logical): Overwrite files exist. FALSE file exists error thrown.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/stream.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Streams data from R to AWS S3. — stream","text":"list raw vectors containing contents file","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/stream.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Streams data from R to AWS S3. — stream","text":"","code":"if (FALSE) { # \\dontrun{ # Require AWS S3 credentials  obj = list(charToRaw(\"contents1\"), charToRaw(\"contents2\"))  dir = s3_file_temp(tmp_dir = \"MyBucket\") path = s3_path(dir, letters[1:2], ext = \"txt\")  s3_file_stream_out(obj, path) s3_file_stream_in(path) } # }"},{"path":"https://dyfanjones.github.io/s3fs/reference/stream_async.html","id":null,"dir":"Reference","previous_headings":"","what":"Streams data from R to AWS S3. — stream_async","title":"Streams data from R to AWS S3. — stream_async","text":"s3_file_stream_in streams AWS S3 file raw vector s3_file_stream_out streams raw vector AWS S3 file","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/stream_async.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Streams data from R to AWS S3. — stream_async","text":"","code":"s3_file_stream_in_async(path, ...)  s3_file_stream_out_async(   obj,   path,   max_batch = fs_bytes(\"100MB\"),   overwrite = FALSE,   ... )"},{"path":"https://dyfanjones.github.io/s3fs/reference/stream_async.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Streams data from R to AWS S3. — stream_async","text":"path (character): character vector paths s3 uri ... parameters passed s3_get_object s3_put_object obj (raw|character): raw vector, rawConnection, url streamed AWS S3. max_batch (fs_bytes): Maximum batch size uploaded multipart. overwrite (logical): Overwrite files exist. FALSE file exists error thrown.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/stream_async.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Streams data from R to AWS S3. — stream_async","text":"return future object s3_file_stream_in() s3_file_stream_out()","code":""},{"path":[]},{"path":"https://dyfanjones.github.io/s3fs/reference/tag.html","id":null,"dir":"Reference","previous_headings":"","what":"Modifying file tags — tag","title":"Modifying file tags — tag","text":"s3_file_tag_delete delete file tags s3_file_tag_info get file tags s3_file_tag_info","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/tag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Modifying file tags — tag","text":"","code":"s3_file_tag_delete(path)  s3_file_tag_info(path)  s3_file_tag_update(path, tags, overwrite = FALSE)"},{"path":"https://dyfanjones.github.io/s3fs/reference/tag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Modifying file tags — tag","text":"path (character): character vector paths s3 uri tags (list): Tags applied overwrite (logical): overwrite tagging modify inplace. Default modify inplace.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/touch.html","id":null,"dir":"Reference","previous_headings":"","what":"Change file modification time — touch","title":"Change file modification time — touch","text":"Similar fs::file_touch create file exist. Use s3_file_create needed.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/touch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Change file modification time — touch","text":"","code":"s3_file_touch(path, ...)"},{"path":"https://dyfanjones.github.io/s3fs/reference/touch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Change file modification time — touch","text":"path (character): character vector paths s3 uri ... parameters passed s3_copy_object","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/touch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Change file modification time — touch","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/touch.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Change file modification time — touch","text":"method update modification time AWS S3 object.","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/touch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Change file modification time — touch","text":"","code":"if (FALSE) { # \\dontrun{ # Require AWS S3 credentials  dir = s3_file_temp(tmp_dir = \"MyBucket\") path = s3_path(dir, letters[1:2], ext = \"txt\")  s3_file_touch(path) } # }"},{"path":"https://dyfanjones.github.io/s3fs/reference/upload.html","id":null,"dir":"Reference","previous_headings":"","what":"Upload file and directory — upload","title":"Upload file and directory — upload","text":"s3_file_upload upload files AWS S3 s3_dir_upload upload directory AWS S3","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/upload.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Upload file and directory — upload","text":"","code":"s3_file_upload(   path,   new_path,   max_batch = fs_bytes(\"100MB\"),   overwrite = FALSE,   ... )  s3_dir_upload(path, new_path, max_batch, overwrite = FALSE, ...)"},{"path":"https://dyfanjones.github.io/s3fs/reference/upload.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Upload file and directory — upload","text":"path (character): character vector local file paths upload AWS S3 new_path (character): character vector AWS S3 paths uri's new locations. max_batch (fs_bytes): Maximum batch size uploaded multipart. overwrite (logical): Overwrite files exist. FALSE file exists error thrown. ... parameters passed s3_put_object s3_create_multipart_upload","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/upload.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Upload file and directory — upload","text":"character vector s3 uri paths","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/upload_async.html","id":null,"dir":"Reference","previous_headings":"","what":"Upload file and directory — upload_async","title":"Upload file and directory — upload_async","text":"s3_file_upload upload files AWS S3 s3_dir_upload upload directory AWS S3","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/upload_async.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Upload file and directory — upload_async","text":"","code":"s3_file_upload_async(   path,   new_path,   max_batch = fs_bytes(\"100MB\"),   overwrite = FALSE,   ... )  s3_dir_upload_async(path, new_path, max_batch, overwrite = FALSE, ...)"},{"path":"https://dyfanjones.github.io/s3fs/reference/upload_async.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Upload file and directory — upload_async","text":"path (character): character vector local file paths upload AWS S3 new_path (character): character vector AWS S3 paths uri's new locations. max_batch (fs_bytes): Maximum batch size uploaded multipart. overwrite (logical): Overwrite files exist. FALSE file exists error thrown. ... parameters passed s3_put_object s3_create_multipart_upload","code":""},{"path":"https://dyfanjones.github.io/s3fs/reference/upload_async.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Upload file and directory — upload_async","text":"return future object s3_file_upload() s3_dir_upload()","code":""},{"path":[]},{"path":"https://dyfanjones.github.io/s3fs/news/index.html","id":"s3fs-017","dir":"Changelog","previous_headings":"","what":"s3fs 0.1.7","title":"s3fs 0.1.7","text":"CRAN release: 2024-08-29 Fix files without extensions created dir/file instead file (#47) thanks @pat-s raising issue","code":""},{"path":"https://dyfanjones.github.io/s3fs/news/index.html","id":"s3fs-016","dir":"Changelog","previous_headings":"","what":"s3fs 0.1.6","title":"s3fs 0.1.6","text":"CRAN release: 2024-07-25 Suppress warning S3FileSystem triggered s3_file_delete() (#42, @salim-b)","code":""},{"path":"https://dyfanjones.github.io/s3fs/news/index.html","id":"s3fs-015","dir":"Changelog","previous_headings":"","what":"s3fs 0.1.5","title":"s3fs 0.1.5","text":"CRAN release: 2024-03-15 Fix s3_file_download allow multiple file paths passed new_path (#34), thanks @sckott contribution. Fix s3_file_info, convert logical(0) NA correctly build data.frame output. improve helper function str_split performance","code":""},{"path":"https://dyfanjones.github.io/s3fs/news/index.html","id":"s3fs-014","dir":"Changelog","previous_headings":"","what":"s3fs 0.1.4","title":"s3fs 0.1.4","text":"CRAN release: 2023-10-23 Fix ensure path returned already existing directories (#28) set R version >= 3.6.0 (#29)","code":""},{"path":"https://dyfanjones.github.io/s3fs/news/index.html","id":"s3fs-013","dir":"Changelog","previous_headings":"","what":"s3fs 0.1.3","title":"s3fs 0.1.3","text":"CRAN release: 2023-03-02 Fix hard coded max batch size Add seed future prevent warning message Ensure nested directories removed class cache","code":""},{"path":"https://dyfanjones.github.io/s3fs/news/index.html","id":"s3fs-012","dir":"Changelog","previous_headings":"","what":"s3fs 0.1.2","title":"s3fs 0.1.2","text":"CRAN release: 2023-02-14 Hot fix replace \\() syntax function()","code":""},{"path":"https://dyfanjones.github.io/s3fs/news/index.html","id":"s3fs-011","dir":"Changelog","previous_headings":"","what":"s3fs 0.1.1","title":"s3fs 0.1.1","text":"Update Description align cran requirements","code":""},{"path":"https://dyfanjones.github.io/s3fs/news/index.html","id":"s3fs-010","dir":"Changelog","previous_headings":"","what":"s3fs 0.1.0","title":"s3fs 0.1.0","text":"Added NEWS.md file track changes package. Initial cran release","code":""}]
